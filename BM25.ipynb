{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     The Hunger Games\n",
      "1            Harry Potter and the Order of the Phoenix\n",
      "2                                To Kill a Mockingbird\n",
      "3                                  Pride and Prejudice\n",
      "4                                             Twilight\n",
      "5                                       The Book Thief\n",
      "6                                          Animal Farm\n",
      "7                             The Chronicles of Narnia\n",
      "8    J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
      "9                                   Gone with the Wind\n",
      "Name: title, dtype: object\n",
      "(52478, 25)\n",
      "51483          Never Do Anything, Ever\n",
      "9770         Black Bird of the Gallows\n",
      "12721                  October Breezes\n",
      "41193    Prins Valiant (Jaargang 1959)\n",
      "22279                  Finding Freedom\n",
      "40072         Amazing Agent Luna Vol 1\n",
      "6467                      Dark Reunion\n",
      "35770     The Honorable Imposter: 1620\n",
      "27604                     Hvid som sne\n",
      "22385                        Sanctuary\n",
      "Name: title, dtype: object\n",
      "(1000, 25)\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\booklist.csv', index_col=False)\n",
    "print(df['title'].head(10))\n",
    "print(df.shape)\n",
    "df = df.sample(n=1000)\n",
    "print(df['title'].head(10))\n",
    "print(df.shape)\n",
    "\n",
    "col_names=['bookId','title','series','author','rating','description','lang','isbn','genres','characters','bookForm','edition','pages','publisher','publishDate','firstPublished','awards','numRating','ratingsByStars','likedPercent','setting','coverImg','bbeScore','bbeVotes','price']\n",
    "wanted_cols = ['bookId','title','series','author','rating','description','genres','characters','setting','coverImg']\n",
    "\n",
    "#TODO: filter out our wanted cols, create our index and save it to a file(?)\n",
    "filtered_df = df[wanted_cols].head(5)\n",
    "\n",
    "print(df['genres'].dtypes)\n",
    "print(df['characters'].dtypes)\n",
    "print(df['setting'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    # doc = ' '.join(filtered_tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "from six import iteritems\n",
    "from six.moves import xrange\n",
    "\n",
    "PARAM_K1 = 2.5\n",
    "PARAM_B = 0.85\n",
    "EPSILON = 0.2\n",
    "\n",
    "class BM25(object):\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus_size = len(corpus)\n",
    "        self.avgdl = sum(float(len(x)) for x in corpus) / self.corpus_size\n",
    "        self.corpus = corpus\n",
    "        self.f = []\n",
    "        self.df = {}\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for document in self.corpus:\n",
    "            frequencies = {}\n",
    "            self.doc_len.append(len(document))\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.f.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in self.df:\n",
    "                    self.df[word] = 0\n",
    "                self.df[word] += 1\n",
    "\n",
    "        for word, freq in iteritems(self.df):\n",
    "            self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "\n",
    "    def get_score(self, document, index, average_idf):\n",
    "        score = 0\n",
    "        for word in document:\n",
    "            if word not in self.f[index]:\n",
    "                continue\n",
    "            idf = self.idf[word] if self.idf[word] >= 0 else EPSILON * average_idf\n",
    "            score += (idf * self.f[index][word] * (PARAM_K1 + 1)\n",
    "                      / (self.f[index][word] + PARAM_K1 * (1 - PARAM_B + PARAM_B * self.doc_len[index] / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, document, average_idf):\n",
    "        scores = []\n",
    "        for index in xrange(self.corpus_size):\n",
    "            score = self.get_score(document, index, average_idf)\n",
    "            scores.append(score)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bm25_weights(corpus):\n",
    "    bm25 = BM25(corpus)\n",
    "    average_idf = sum(float(val) for val in bm25.idf.values()) / len(bm25.idf)\n",
    "\n",
    "    weights = []\n",
    "    for doc in corpus:\n",
    "        scores = bm25.get_scores(doc, average_idf)\n",
    "        weights.append(scores)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(literal_eval)\n",
    "df['characters'] = df['characters'].apply(literal_eval)\n",
    "df['setting'] = df['setting'].apply(literal_eval)\n",
    "df['author'] = df['author'].apply(lambda x : x.split(\", \"))\n",
    "df['description'] = df['description'].apply(lambda x : normalize_document(str(x)))\n",
    "df['soup'] = df['author'] + df['description'] + df['genres'] + df['characters'] + df['setting'] \n",
    "# df['soup'] = df['soup'].apply(lambda x: ' '.join(x))\n",
    "# print(df['description'].head())\n",
    "# test = list(df['description'])\n",
    "# print(test)\n",
    "\n",
    "# print(df['description'].iloc[0])\n",
    "# print(df['soup'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm_corpus = df['soup'].to_list()\n",
    "wts = get_bm25_weights(norm_corpus)\n",
    "bm25_wts_df = pd.DataFrame(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, doc_sims, no_of_recommendation):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(df['title'].values == movie_title)[0][0] # (1000,1000)\n",
    "    # get movie similarities\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values # (1000,)\n",
    "    similar_movies = np.sort(-movie_similarities)[1:no_of_recommendation+1]\n",
    "    print(similar_movies)\n",
    "    # get top 5 similar movie IDs\n",
    "    similar_movies_idxs = np.argsort(-movie_similarities)[1:no_of_recommendation+1]\n",
    "    print(similar_movies_idxs)\n",
    "    # get top 5 movies\n",
    "\n",
    "    similar_movies_title = df['title'].values[similar_movies_idxs]\n",
    "    print(similar_movies.shape)\n",
    "    similar_movies = pd.DataFrame({'title': similar_movies_title, 'similarity score': -similar_movies})\n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0           1           2          3           4          5    \\\n",
      "0  403.592947   19.405255   13.366547   0.000000    6.345203  12.708599   \n",
      "1   17.158991  329.661316   19.512704   0.000000   11.102772   5.486301   \n",
      "2   15.903773   25.849042  499.548941   0.000000   22.370886  13.896411   \n",
      "3    0.000000    0.000000    0.000000  83.463297    0.000000   0.000000   \n",
      "4    6.647641   18.524590   25.729370   0.000000  417.944323   7.455913   \n",
      "\n",
      "         6          7         8          9    ...        990        991  \\\n",
      "0  12.155116   7.060760  2.168962   5.376490  ...   5.538318  12.727176   \n",
      "1  27.132536  18.453405  2.168962  16.688440  ...  24.433872   7.314540   \n",
      "2   9.840908  10.542621  2.168962   7.212738  ...   0.000000  19.718563   \n",
      "3   0.000000   0.000000  0.000000   0.000000  ...   0.000000   0.000000   \n",
      "4  20.814080  14.710168  0.000000  12.338991  ...   9.169454  24.905956   \n",
      "\n",
      "         992       993       994        995       996       997       998  999  \n",
      "0   7.741337  3.392377  7.594304  10.879540  1.100886  2.013732  0.000000  0.0  \n",
      "1   3.967940  3.793739  8.164698   1.586592  1.834651  3.355930  0.000000  0.0  \n",
      "2  10.412969  7.843148  4.546181   2.722219  0.733765  3.371575  2.064691  0.0  \n",
      "3   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000  0.0  \n",
      "4  15.604374  6.947406  3.606725  15.895485  0.733765  5.848876  9.115092  0.0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bm25_wts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-48.20045531 -39.78119691 -36.52177067 -35.26544003 -35.04585239\n",
      " -35.01305968 -34.81191015 -33.82330947 -33.63081642 -32.29609014]\n",
      "[ 48 724 512 514 787 839 488 629 149  62]\n",
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jamie Dornan: Shades of Desire</td>\n",
       "      <td>48.200455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ramona the Brave</td>\n",
       "      <td>39.781197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voyage on the Great Titanic: The Diary of Marg...</td>\n",
       "      <td>36.521771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss Daisy Is Crazy!</td>\n",
       "      <td>35.265440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Into the Wild Nerd Yonder</td>\n",
       "      <td>35.045852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Catch Your Death</td>\n",
       "      <td>35.013060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Long Way from Chicago</td>\n",
       "      <td>34.811910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Big Red</td>\n",
       "      <td>33.823309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oblivion</td>\n",
       "      <td>33.630816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lunch Walks Among Us</td>\n",
       "      <td>32.296090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  similarity score\n",
       "0                     Jamie Dornan: Shades of Desire         48.200455\n",
       "1                                   Ramona the Brave         39.781197\n",
       "2  Voyage on the Great Titanic: The Diary of Marg...         36.521771\n",
       "3                               Miss Daisy Is Crazy!         35.265440\n",
       "4                          Into the Wild Nerd Yonder         35.045852\n",
       "5                                   Catch Your Death         35.013060\n",
       "6                            A Long Way from Chicago         34.811910\n",
       "7                                            Big Red         33.823309\n",
       "8                                           Oblivion         33.630816\n",
       "9                               Lunch Walks Among Us         32.296090"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = df['title'].iloc[0]\n",
    "\n",
    "movie_recommender(movie_title=movie, doc_sims=bm25_wts_df, no_of_recommendation=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
