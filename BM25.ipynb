{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "from evaluation import mean_average_precision,ndcg_at_k\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     The Hunger Games\n",
      "1            Harry Potter and the Order of the Phoenix\n",
      "2                                To Kill a Mockingbird\n",
      "3                                  Pride and Prejudice\n",
      "4                                             Twilight\n",
      "5                                       The Book Thief\n",
      "6                                          Animal Farm\n",
      "7                             The Chronicles of Narnia\n",
      "8    J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
      "9                                   Gone with the Wind\n",
      "Name: title, dtype: object\n",
      "(52478, 25)\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\booklist.csv', index_col=False,encoding=\"latin-1\")\n",
    "print(df['title'].head(10))\n",
    "print(df.shape)\n",
    "df = df.head(100)\n",
    "# df = df.sample(n=1000)\n",
    "# print(df['title'].head(10))\n",
    "# print(df.shape)\n",
    "\n",
    "col_names=['bookId','title','series','author','rating','description','lang','isbn','genres','characters','bookForm','edition','pages','publisher','publishDate','firstPublished','awards','numRating','ratingsByStars','likedPercent','setting','coverImg','bbeScore','bbeVotes','price']\n",
    "wanted_cols = ['bookId','title','series','author','rating','description','genres','characters','setting','coverImg']\n",
    "\n",
    "#TODO: filter out our wanted cols, create our index and save it to a file(?)\n",
    "filtered_df = df[wanted_cols].head(5)\n",
    "\n",
    "print(df['genres'].dtypes)\n",
    "print(df['characters'].dtypes)\n",
    "print(df['setting'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    # doc = ' '.join(filtered_tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from six import iteritems\n",
    "from six.moves import xrange\n",
    "\n",
    "PARAM_K1 = 2.5\n",
    "PARAM_B = 0.85\n",
    "EPSILON = 0.2\n",
    "\n",
    "class BM25(object):\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus_size = len(corpus)\n",
    "        self.avgdl = sum(float(len(x)) for x in corpus) / self.corpus_size\n",
    "        self.corpus = corpus\n",
    "        self.f = []\n",
    "        self.df = {}\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for document in self.corpus:\n",
    "            frequencies = {}\n",
    "            self.doc_len.append(len(document))\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.f.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in self.df:\n",
    "                    self.df[word] = 0\n",
    "                self.df[word] += 1\n",
    "\n",
    "        for word, freq in iteritems(self.df):\n",
    "            self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "\n",
    "    def get_score(self, document, index, average_idf):\n",
    "        score = 0\n",
    "        for word in document:\n",
    "            if word not in self.f[index]:\n",
    "                continue\n",
    "            idf = self.idf[word] if self.idf[word] >= 0 else EPSILON * average_idf\n",
    "            score += (idf * self.f[index][word] * (PARAM_K1 + 1)\n",
    "                      / (self.f[index][word] + PARAM_K1 * (1 - PARAM_B + PARAM_B * self.doc_len[index] / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, document, average_idf):\n",
    "        scores = []\n",
    "        for index in xrange(self.corpus_size):\n",
    "            score = self.get_score(document, index, average_idf)\n",
    "            scores.append(score)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bm25_weights(corpus):\n",
    "    bm25 = BM25(corpus)\n",
    "    average_idf = sum(float(val) for val in bm25.idf.values()) / len(bm25.idf)\n",
    "\n",
    "    weights = []\n",
    "    for doc in corpus:\n",
    "        scores = bm25.get_scores(doc, average_idf)\n",
    "        weights.append(scores)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(literal_eval)\n",
    "df['characters'] = df['characters'].apply(literal_eval)\n",
    "df['setting'] = df['setting'].apply(literal_eval)\n",
    "df['author'] = df['author'].apply(lambda x : x.split(\", \"))\n",
    "df['description'] = df['description'].apply(lambda x : normalize_document(str(x)))\n",
    "df['soup'] = df['author'] + df['description'] + df['genres'] + df['characters'] + df['setting'] \n",
    "# df['soup'] = df['soup'].apply(lambda x: ' '.join(x))\n",
    "# print(df['description'].head())\n",
    "# test = list(df['description'])\n",
    "# print(test)\n",
    "\n",
    "# print(df['description'].iloc[0])\n",
    "# print(df['soup'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm_corpus = df['soup'].to_list()\n",
    "wts = get_bm25_weights(norm_corpus)\n",
    "bm25_wts_df = pd.DataFrame(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf = pd.read_csv(r'.\\small_eval.csv', index_col=False, encoding=\"utf-8\")\n",
    "evaldf['recommended'] = evaldf['recommended'].apply(literal_eval)\n",
    "\n",
    "def get_recommendations(book_title, doc_sims, no_of_recommendation):\n",
    "    # find movie id\n",
    "    book_idx = np.where(df['title'].values == book_title)[0][0] # (1000,1000)\n",
    "    # get movie similarities\n",
    "    book_similarities = doc_sims.iloc[book_idx].values # (1000,)\n",
    "    similar_books = np.sort(-book_similarities)[1:no_of_recommendation+1]\n",
    "    # print(similar_movies)\n",
    "    # get top 5 similar movie IDs\n",
    "    book_movies_idxs = np.argsort(-book_similarities)[1:no_of_recommendation+1]\n",
    "    # print(similar_movies_idxs)\n",
    "    # get top 5 movies\n",
    "\n",
    "    similar_book_title = df['title'].values[book_movies_idxs]\n",
    "    # print(similar_movies.shape)\n",
    "\n",
    "    actualidx = evaldf[evaldf['title']==book_title]['recommended']\n",
    "    actual = evaldf['recommended'].iloc[actualidx.index.values[0]]\n",
    "\n",
    "    # print(predictions)\n",
    "    # print(actual)\n",
    "\n",
    "    r = []\n",
    "    for book in similar_book_title:\n",
    "        if book in actual:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    similar_books = pd.DataFrame({'title': similar_book_title, 'similarity score': -similar_books, 'relevance': r})\n",
    "    # return the top 5 movies\n",
    "    return similar_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0           1           2           3           4          5   \\\n",
      "0  410.088709    1.749539    5.876535    5.333438   12.380981   7.413062   \n",
      "1    1.885226  372.058359    1.930180    1.583032    5.563658   2.820266   \n",
      "2    5.866141    1.672180  326.338859   12.889248   10.913682  12.083029   \n",
      "3    4.949344    1.363296   12.812761  354.514024    2.548888   9.960987   \n",
      "4    9.149236    3.618670    8.196905    1.925036  275.944028   3.865783   \n",
      "\n",
      "          6          7         8          9   ...         90        91  \\\n",
      "0   7.270192   6.232013  2.786062  12.138057  ...  17.069216  5.335407   \n",
      "1   1.641839  10.127221  6.515663   5.201536  ...  11.831332  5.489673   \n",
      "2  17.796188  16.075786  8.324483   6.408624  ...   1.361506  9.063883   \n",
      "3  22.353134   6.560155  5.619648  12.248910  ...   1.940820  7.246074   \n",
      "4   1.996548   7.190991  4.578263   2.528899  ...   4.334745  2.060329   \n",
      "\n",
      "          92          93         94         95         96        97  \\\n",
      "0  10.133908    7.279578   2.490595  17.002669   1.897982  2.382236   \n",
      "1  11.521079  129.494581   3.669024   3.464294  18.944902  2.776339   \n",
      "2  10.964813    7.725186  16.019504  12.672608   3.204104  8.119187   \n",
      "3   6.635980    4.763399  15.565145   3.927935   2.612244  8.276850   \n",
      "4   5.948601    7.015396   1.834635  10.113591   1.897982  1.388170   \n",
      "\n",
      "          98        99  \n",
      "0   6.103135  1.023749  \n",
      "1   2.214293  8.768113  \n",
      "2  12.451906  4.773182  \n",
      "3   9.050283  4.773182  \n",
      "4  13.118372  1.023749  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bm25_wts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity score</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>144.155474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>129.494581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>97.069427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lord of the Flies</td>\n",
       "      <td>22.492864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anne of Green Gables</td>\n",
       "      <td>19.288019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>City of Bones</td>\n",
       "      <td>19.286989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Winnie-the-Pooh</td>\n",
       "      <td>18.944902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Matilda</td>\n",
       "      <td>18.355564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A Wrinkle in Time</td>\n",
       "      <td>16.842733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Where the Wild Things Are</td>\n",
       "      <td>13.549117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Fellowship of the Ring</td>\n",
       "      <td>12.222217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Golden Compass</td>\n",
       "      <td>11.831332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Divergent</td>\n",
       "      <td>11.777071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Giver</td>\n",
       "      <td>11.649095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Perks of Being a Wallflower</td>\n",
       "      <td>11.576716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atlas Shrugged</td>\n",
       "      <td>11.521079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Chronicles of Narnia</td>\n",
       "      <td>10.127221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Help</td>\n",
       "      <td>9.721578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Princess Bride</td>\n",
       "      <td>9.669870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Lightning Thief</td>\n",
       "      <td>9.454916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  similarity score  relevance\n",
       "0       Harry Potter and the Deathly Hallows        144.155474          0\n",
       "1   Harry Potter and the Prisoner of Azkaban        129.494581          0\n",
       "2      Harry Potter and the Sorcerer's Stone         97.069427          0\n",
       "3                          Lord of the Flies         22.492864          0\n",
       "4                       Anne of Green Gables         19.288019          0\n",
       "5                              City of Bones         19.286989          0\n",
       "6                            Winnie-the-Pooh         18.944902          0\n",
       "7                                    Matilda         18.355564          0\n",
       "8                          A Wrinkle in Time         16.842733          0\n",
       "9                  Where the Wild Things Are         13.549117          0\n",
       "10                The Fellowship of the Ring         12.222217          0\n",
       "11                        The Golden Compass         11.831332          0\n",
       "12                                 Divergent         11.777071          0\n",
       "13                                 The Giver         11.649095          0\n",
       "14           The Perks of Being a Wallflower         11.576716          0\n",
       "15                            Atlas Shrugged         11.521079          0\n",
       "16                  The Chronicles of Narnia         10.127221          1\n",
       "17                                  The Help          9.721578          0\n",
       "18                        The Princess Bride          9.669870          0\n",
       "19                       The Lightning Thief          9.454916          1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie = df['title'].iloc[0]\n",
    "\n",
    "get_recommendations(book_title=\"Harry Potter and the Order of the Phoenix\", doc_sims=bm25_wts_df, no_of_recommendation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Deathly Hallows\n"
     ]
    }
   ],
   "source": [
    "x=get_recommendations(book_title=\"Harry Potter and the Order of the Phoenix\", doc_sims=bm25_wts_df, no_of_recommendation=20)\n",
    "\n",
    "print(x['title'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf = pd.read_csv(r'.\\small_eval.csv', index_col=False, encoding=\"utf-8\")\n",
    "evaldf['recommended'] = evaldf['recommended'].apply(literal_eval)\n",
    "\n",
    "def getr(booktitle,k = 20):\n",
    "    predictions = get_recommendations(book_title=booktitle, doc_sims=bm25_wts_df, no_of_recommendation=k)\n",
    "    actualidx = evaldf[evaldf['title']==booktitle]['recommended']\n",
    "    actual = evaldf['recommended'].iloc[actualidx.index.values[0]]\n",
    "\n",
    "    # print(predictions)\n",
    "    # print(actual)\n",
    "\n",
    "    r = []\n",
    "    for book in range(k):\n",
    "        if predictions['title'].iloc[book] in actual:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6313247675185968\n",
      "0.23801437763899258\n",
      "0.5553782207444934\n",
      "0.8784098137096863\n",
      "0.5077643968214793\n",
      "0.38384462508052564\n",
      "0.5697444455330438\n",
      "0.6309297535714575\n",
      "0.4250459329151599\n",
      "0.6585381834928036\n",
      "0.39241192488026627\n",
      "0.8531776795146803\n",
      "0.7546117266328853\n",
      "0.8977107666850511\n",
      "0.4540111928030904\n",
      "0.40309698369020075\n",
      "0.7842137690517234\n",
      "0.46673735257960025\n",
      "0.7310358129389314\n",
      "0.7423373896514631\n",
      "0.5800952514711237\n",
      "0.5516408353038085\n",
      "0.5453679230449677\n",
      "0.8150873052679217\n",
      "0.717619793917951\n",
      "0.5629104584393229\n",
      "0.4053927342610788\n",
      "0.49628413432295043\n",
      "0.5876652500336149\n",
      "0.32140541602217854\n",
      "0.40833068348615187\n"
     ]
    }
   ],
   "source": [
    "rs=[]\n",
    "for book in range(30):\n",
    "    r=getr(df['title'].iloc[book])\n",
    "    rs.append(r)\n",
    "    print(ndcg_at_k(r,20))\n",
    "\n",
    "print(mean_average_precision(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      movies      ndcg\n",
      "0                           The Hunger Games  0.631325\n",
      "1  Harry Potter and the Order of the Phoenix  0.238014\n",
      "2                      To Kill a Mockingbird  0.555378\n",
      "3                        Pride and Prejudice  0.878410\n",
      "4                                   Twilight  0.507764\n",
      "0.40833068348615187\n"
     ]
    }
   ],
   "source": [
    "showcase = df['title'].values[0:30]\n",
    "ndcg_at_k_list = []\n",
    "rs=[]\n",
    "for book in range(30):\n",
    "    recommended = get_recommendations(book_title=df['title'].iloc[book], doc_sims=bm25_wts_df, no_of_recommendation=20)\n",
    "    r= recommended['relevance'].values\n",
    "    rs.append(r)\n",
    "    ndcg_at_k_list.append(ndcg_at_k(r,20))\n",
    "    \n",
    "results = pd.DataFrame({'movies': showcase, 'ndcg': ndcg_at_k_list})\n",
    "\n",
    "print(results.head())\n",
    "\n",
    "print(mean_average_precision(rs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
