{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     The Hunger Games\n",
      "1            Harry Potter and the Order of the Phoenix\n",
      "2                                To Kill a Mockingbird\n",
      "3                                  Pride and Prejudice\n",
      "4                                             Twilight\n",
      "5                                       The Book Thief\n",
      "6                                          Animal Farm\n",
      "7                             The Chronicles of Narnia\n",
      "8    J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
      "9                                   Gone with the Wind\n",
      "Name: title, dtype: object\n",
      "(52478, 25)\n",
      "14717                                               Eloise\n",
      "8771           The Death and Life of Great American Cities\n",
      "25073                                         Rubbernecker\n",
      "9841                             Out of Sight, Out of Mind\n",
      "21190    The Rhino Crash: A Memoir of Conservation, Unl...\n",
      "45860                                               Bolero\n",
      "4091                                       Bad Moon Rising\n",
      "42477                  The Authentic Death of Hendry Jones\n",
      "19718                                          Delinquents\n",
      "20463                                           Adams Erbe\n",
      "Name: title, dtype: object\n",
      "(20000, 25)\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\booklist.csv', index_col=False)\n",
    "print(df['title'].head(10))\n",
    "print(df.shape)\n",
    "df = df.head(10000)\n",
    "# df = df.sample(n=20000)\n",
    "# print(df['title'].head(10))\n",
    "# print(df.shape)\n",
    "\n",
    "col_names=['bookId','title','series','author','rating','description','lang','isbn','genres','characters','bookForm','edition','pages','publisher','publishDate','firstPublished','awards','numRating','ratingsByStars','likedPercent','setting','coverImg','bbeScore','bbeVotes','price']\n",
    "wanted_cols = ['bookId','title','series','author','rating','description','genres','characters','setting','coverImg']\n",
    "\n",
    "#TODO: filter out our wanted cols, create our index and save it to a file(?)\n",
    "filtered_df = df[wanted_cols].head(5)\n",
    "\n",
    "print(df['genres'].dtypes)\n",
    "print(df['characters'].dtypes)\n",
    "print(df['setting'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# Characters, author and genre\n",
    "df['genres'] = df['genres'].apply(literal_eval)\n",
    "df['characters'] = df['characters'].apply(literal_eval)\n",
    "df['setting'] = df['setting'].apply(literal_eval)\n",
    "df['author'] = df['author'].apply(lambda x : x.split(\", \"))\n",
    "print(df['author'].dtypes)\n",
    "print(df['description'].dtypes)\n",
    "\n",
    "df['soup'] = df['author'] + df['genres'] + df['characters'] + df['setting'] \n",
    "df['soup'] = df['soup'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meet eloise precocious darling plaza hotel eloise little girl lives plaza hotel new york yet pretty already person henry james would want study queen victoria would recognize equal new york jets would want side lewis carroll would love got initial shock knows everything plaza interested people boring inner resources take home always glad\n",
      "Kay Thompson Hilary Knight Picture Books Childrens Fiction Classics Humor New York Juvenile Kids Adventure Realistic Fiction Mr. Salomone Weenie Skipperdee Thomas Bill Nanny Ren√© Johanna Joe Vincent Philip Lily Eloise meet eloise precocious darling plaza hotel eloise little girl lives plaza hotel new york yet pretty already person henry james would want study queen victoria would recognize equal new york jets would want side lewis carroll would love got initial shock knows everything plaza interested people boring inner resources take home always glad\n"
     ]
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x : normalize_document(str(x)))\n",
    "\n",
    "\n",
    "df['soup'] = df['soup'] + \" \" + df['description']\n",
    "print(df['description'].iloc[0])\n",
    "print(df['soup'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df['soup'].values.astype('U'))\n",
    "\n",
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(df['soup'])\n",
    "\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "# cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.00276782 0.00505917 ... 0.00456839 0.00259938 0.00687278]\n",
      " [0.00276782 1.         0.00438346 ... 0.00352644 0.00418344 0.00274461]\n",
      " [0.00505917 0.00438346 1.         ... 0.00653436 0.00810144 0.00180712]\n",
      " ...\n",
      " [0.00456839 0.00352644 0.00653436 ... 1.         0.17711616 0.00691302]\n",
      " [0.00259938 0.00418344 0.00810144 ... 0.17711616 1.         0.0097533 ]\n",
      " [0.00687278 0.00274461 0.00180712 ... 0.00691302 0.0097533  1.        ]]\n",
      "(10000, 10000)\n",
      "title\n",
      "The Hunger Games                                                         0\n",
      "Harry Potter and the Order of the Phoenix                                1\n",
      "To Kill a Mockingbird                                                    2\n",
      "Pride and Prejudice                                                      3\n",
      "Twilight                                                                 4\n",
      "The Book Thief                                                           5\n",
      "Animal Farm                                                              6\n",
      "The Chronicles of Narnia                                                 7\n",
      "J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings    8\n",
      "Gone with the Wind                                                       9\n",
      "dtype: int64\n",
      "(10000,)\n",
      "[[1.         0.00276782 0.00505917 ... 0.00456839 0.00259938 0.00687278]\n",
      " [0.00276782 1.         0.00438346 ... 0.00352644 0.00418344 0.00274461]\n",
      " [0.00505917 0.00438346 1.         ... 0.00653436 0.00810144 0.00180712]\n",
      " ...\n",
      " [0.00456839 0.00352644 0.00653436 ... 1.         0.17711616 0.00691302]\n",
      " [0.00259938 0.00418344 0.00810144 ... 0.17711616 1.         0.0097533 ]\n",
      " [0.00687278 0.00274461 0.00180712 ... 0.00691302 0.0097533  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim)\n",
    "print(cosine_sim.shape)\n",
    "indices = pd.Series([i for i in range(len(df))] ,index=df['title'])\n",
    "print(indices.head(10))\n",
    "print(indices.shape)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, no_of_recommendation):\n",
    "    idx = indices[title]\n",
    "    df['similarity score'] = np.array(cosine_sim[idx])\n",
    "    df['weightedRating'] = (((df[\"rating\"] -  1)/4) + (df[\"likedPercent\"] * 0.01) + ((df['numRatings'] - df['numRatings'].min()) / (df['numRatings'].max() - df['numRatings'].min())))/3\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:no_of_recommendation+1]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    book_cossim = df[[\"title\", \"similarity score\", \"weightedRating\"]].iloc[book_indices]\n",
    "    book_cossim = book_cossim.sort_values(\"weightedRating\", ascending=False)\n",
    "    return book_cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity score</th>\n",
       "      <th>weightedRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46343</th>\n",
       "      <td>The Connection</td>\n",
       "      <td>0.054956</td>\n",
       "      <td>0.600926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>Too Consumed</td>\n",
       "      <td>0.054684</td>\n",
       "      <td>0.592836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Mine</td>\n",
       "      <td>0.053351</td>\n",
       "      <td>0.592157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47255</th>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>0.072951</td>\n",
       "      <td>0.590361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45442</th>\n",
       "      <td>Seductive Nights Trilogy Bundle (Seductive Nig...</td>\n",
       "      <td>0.057863</td>\n",
       "      <td>0.585887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41270</th>\n",
       "      <td>Bad Judgment</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>0.564635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42006</th>\n",
       "      <td>The Bad Boy in the Glasses</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.562513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20570</th>\n",
       "      <td>Sweetness</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.547539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>Since Drew</td>\n",
       "      <td>0.053994</td>\n",
       "      <td>0.545907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28361</th>\n",
       "      <td>Wildcard: Volume One</td>\n",
       "      <td>0.054957</td>\n",
       "      <td>0.532547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  similarity score  \\\n",
       "32                Harry Potter and the Sorcerer's Stone          0.401764   \n",
       "71                 Harry Potter and the Deathly Hallows          0.574971   \n",
       "93             Harry Potter and the Prisoner of Azkaban          0.498729   \n",
       "103                 Harry Potter and the Goblet of Fire          0.508664   \n",
       "126             Harry Potter and the Chamber of Secrets          0.498498   \n",
       "105              Harry Potter and the Half-Blood Prince          0.423546   \n",
       "409                         Harry Potter Series Box Set          0.066976   \n",
       "7008  Harry Potter Boxed Set, Books 1-5 (Harry Potte...          0.134441   \n",
       "2286                            Harry Potter Collection          0.107575   \n",
       "1600                    The Harry Potter Collection 1-4          0.102698   \n",
       "3576  Harry Potter and the Order of the Phoenix (Har...          0.155249   \n",
       "6600                           The Harry Potter trilogy          0.082734   \n",
       "7418                        Harry Potter: Film Wizardry          0.218910   \n",
       "2580        Harry Potter and the Methods of Rationality          0.239112   \n",
       "9637  Fantastic Beasts - The Crimes of Grindelwald: ...          0.057776   \n",
       "1184            Fantastic Beasts and Where to Find Them          0.136168   \n",
       "1323                         Quidditch Through the Ages          0.052539   \n",
       "1332  Harry Potter and the Cursed Child: Parts One a...          0.160888   \n",
       "5203      James Potter and the Hall of Elders' Crossing          0.218950   \n",
       "6186            James Potter and the Vault of Destinies          0.069612   \n",
       "\n",
       "      weightedRating  \n",
       "32          0.942500  \n",
       "71          0.761300  \n",
       "93          0.760222  \n",
       "103         0.749370  \n",
       "126         0.741410  \n",
       "105         0.739447  \n",
       "409         0.649406  \n",
       "7008        0.644161  \n",
       "2286        0.638962  \n",
       "1600        0.635928  \n",
       "3576        0.632952  \n",
       "6600        0.628662  \n",
       "7418        0.614415  \n",
       "2580        0.596475  \n",
       "9637        0.572065  \n",
       "1184        0.570611  \n",
       "1323        0.546889  \n",
       "1332        0.524844  \n",
       "5203        0.516213  \n",
       "6186        0.513767  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df['title'].iloc[0])\n",
    "get_recommendations(\"Harry Potter and the Order of the Phoenix\", 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bada9726690d286a47909a62bfde12f42d4027df705c6dd14450e360b34616a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
