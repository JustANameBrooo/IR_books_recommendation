{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     The Hunger Games\n",
      "1            Harry Potter and the Order of the Phoenix\n",
      "2                                To Kill a Mockingbird\n",
      "3                                  Pride and Prejudice\n",
      "4                                             Twilight\n",
      "5                                       The Book Thief\n",
      "6                                          Animal Farm\n",
      "7                             The Chronicles of Narnia\n",
      "8    J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
      "9                                   Gone with the Wind\n",
      "Name: title, dtype: object\n",
      "(52478, 25)\n",
      "17163                                 Dirty English\n",
      "23564                                    The Escape\n",
      "20904             Visual Perception with Tensorflow\n",
      "21610                            Romiette and Julio\n",
      "18913    The Divine Family: Experiential Narratives\n",
      "8326                                 Galaxy Pirates\n",
      "12378                             Swallowing Stones\n",
      "17077                                On Mystic Lake\n",
      "12856                                 The Wild Road\n",
      "13142                                         الهول\n",
      "Name: title, dtype: object\n",
      "(20000, 25)\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\booklist.csv', index_col=False)\n",
    "print(df['title'].head(10))\n",
    "print(df.shape)\n",
    "df = df.sample(n=20000)\n",
    "print(df['title'].head(10))\n",
    "print(df.shape)\n",
    "\n",
    "col_names=['bookId','title','series','author','rating','description','lang','isbn','genres','characters','bookForm','edition','pages','publisher','publishDate','firstPublished','awards','numRating','ratingsByStars','likedPercent','setting','coverImg','bbeScore','bbeVotes','price']\n",
    "wanted_cols = ['bookId','title','series','author','rating','description','genres','characters','setting','coverImg']\n",
    "\n",
    "#TODO: filter out our wanted cols, create our index and save it to a file(?)\n",
    "filtered_df = df[wanted_cols].head(5)\n",
    "\n",
    "print(df['genres'].dtypes)\n",
    "print(df['characters'].dtypes)\n",
    "print(df['setting'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# Characters, author and genre\n",
    "df['genres'] = df['genres'].apply(literal_eval)\n",
    "df['characters'] = df['characters'].apply(literal_eval)\n",
    "df['setting'] = df['setting'].apply(literal_eval)\n",
    "df['author'] = df['author'].apply(lambda x : x.split(\", \"))\n",
    "print(df['author'].dtypes)\n",
    "print(df['description'].dtypes)\n",
    "\n",
    "df['soup'] = df['author'] + df['genres'] + df['characters'] + df['setting'] \n",
    "df['soup'] = df['soup'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scarred fighter girl rules one night unbridled passion three things need know elizabeth bennett smart whip always control lives set carefully crafted rules learned hard way people love always hurt end meets declan blay new neighbor apartment complex tattooed british street fighter campus bad boy supposed avoid saves frat party gone bad rules sex love fly window gives one night unbridled passion longs cardboard thin wall separating bedrooms dreams possessing vulnerable girl next door forever one night two damaged hearts passion lifetime modern love story inspired pride prejudice\n",
      "Ilsa Madden-Mills (Goodreads Author) Romance New Adult College Contemporary Contemporary Romance Fighters Sports Abuse Sports Romance Adult scarred fighter girl rules one night unbridled passion three things need know elizabeth bennett smart whip always control lives set carefully crafted rules learned hard way people love always hurt end meets declan blay new neighbor apartment complex tattooed british street fighter campus bad boy supposed avoid saves frat party gone bad rules sex love fly window gives one night unbridled passion longs cardboard thin wall separating bedrooms dreams possessing vulnerable girl next door forever one night two damaged hearts passion lifetime modern love story inspired pride prejudice\n"
     ]
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x : normalize_document(str(x)))\n",
    "\n",
    "\n",
    "df['soup'] = df['soup'] + \" \" + df['description']\n",
    "print(df['description'].iloc[0])\n",
    "print(df['soup'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df['soup'].values.astype('U'))\n",
    "\n",
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(df['soup'])\n",
    "\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "# cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 1.10858255e-02 3.87142290e-03 ... 1.68103888e-02\n",
      "  2.78246393e-02 1.14507389e-02]\n",
      " [1.10858255e-02 1.00000000e+00 2.87558966e-03 ... 3.04158039e-03\n",
      "  2.82451787e-03 8.06185697e-04]\n",
      " [3.87142290e-03 2.87558966e-03 1.00000000e+00 ... 0.00000000e+00\n",
      "  4.69141312e-03 5.51289275e-03]\n",
      " ...\n",
      " [1.68103888e-02 3.04158039e-03 0.00000000e+00 ... 1.00000000e+00\n",
      "  1.83381277e-02 9.57419676e-03]\n",
      " [2.78246393e-02 2.82451787e-03 4.69141312e-03 ... 1.83381277e-02\n",
      "  1.00000000e+00 5.47205866e-03]\n",
      " [1.14507389e-02 8.06185697e-04 5.51289275e-03 ... 9.57419676e-03\n",
      "  5.47205866e-03 1.00000000e+00]]\n",
      "(20000, 20000)\n",
      "title\n",
      "Dirty English                                 0\n",
      "The Escape                                    1\n",
      "Visual Perception with Tensorflow             2\n",
      "Romiette and Julio                            3\n",
      "The Divine Family: Experiential Narratives    4\n",
      "Galaxy Pirates                                5\n",
      "Swallowing Stones                             6\n",
      "On Mystic Lake                                7\n",
      "The Wild Road                                 8\n",
      "الهول                                         9\n",
      "dtype: int64\n",
      "(20000,)\n",
      "[[1.00000000e+00 1.10858255e-02 3.87142290e-03 ... 1.68103888e-02\n",
      "  2.78246393e-02 1.14507389e-02]\n",
      " [1.10858255e-02 1.00000000e+00 2.87558966e-03 ... 3.04158039e-03\n",
      "  2.82451787e-03 8.06185697e-04]\n",
      " [3.87142290e-03 2.87558966e-03 1.00000000e+00 ... 0.00000000e+00\n",
      "  4.69141312e-03 5.51289275e-03]\n",
      " ...\n",
      " [1.68103888e-02 3.04158039e-03 0.00000000e+00 ... 1.00000000e+00\n",
      "  1.83381277e-02 9.57419676e-03]\n",
      " [2.78246393e-02 2.82451787e-03 4.69141312e-03 ... 1.83381277e-02\n",
      "  1.00000000e+00 5.47205866e-03]\n",
      " [1.14507389e-02 8.06185697e-04 5.51289275e-03 ... 9.57419676e-03\n",
      "  5.47205866e-03 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim)\n",
    "print(cosine_sim.shape)\n",
    "indices = pd.Series([i for i in range(len(df))] ,index=df['title'])\n",
    "print(indices.head(10))\n",
    "print(indices.shape)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, no_of_recommendation):\n",
    "    idx = indices[title]\n",
    "    df['similarity score'] = np.array(cosine_sim[idx])\n",
    "    df['weightedRating'] = (((df[\"rating\"] -  1)/4) + (df[\"likedPercent\"] * 0.01) + ((df['numRatings'] - df['numRatings'].min()) / (df['numRatings'].max() - df['numRatings'].min())))/3\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:no_of_recommendation+1]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    book_cossim = df[[\"title\", \"similarity score\", \"weightedRating\"]].iloc[book_indices]\n",
    "    book_cossim = book_cossim.sort_values(\"weightedRating\", ascending=False)\n",
    "    return book_cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirty English\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity score</th>\n",
       "      <th>weightedRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46343</th>\n",
       "      <td>The Connection</td>\n",
       "      <td>0.054956</td>\n",
       "      <td>0.600926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>Too Consumed</td>\n",
       "      <td>0.054684</td>\n",
       "      <td>0.592836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Mine</td>\n",
       "      <td>0.053351</td>\n",
       "      <td>0.592157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47255</th>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>0.072951</td>\n",
       "      <td>0.590361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45442</th>\n",
       "      <td>Seductive Nights Trilogy Bundle (Seductive Nig...</td>\n",
       "      <td>0.057863</td>\n",
       "      <td>0.585887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41270</th>\n",
       "      <td>Bad Judgment</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>0.564635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42006</th>\n",
       "      <td>The Bad Boy in the Glasses</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.562513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20570</th>\n",
       "      <td>Sweetness</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.547539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>Since Drew</td>\n",
       "      <td>0.053994</td>\n",
       "      <td>0.545907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28361</th>\n",
       "      <td>Wildcard: Volume One</td>\n",
       "      <td>0.054957</td>\n",
       "      <td>0.532547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  similarity score  \\\n",
       "46343                                     The Connection          0.054956   \n",
       "9741                                        Too Consumed          0.054684   \n",
       "3423                                                Mine          0.053351   \n",
       "47255                                          Sacrifice          0.072951   \n",
       "45442  Seductive Nights Trilogy Bundle (Seductive Nig...          0.057863   \n",
       "41270                                       Bad Judgment          0.058771   \n",
       "42006                         The Bad Boy in the Glasses          0.053061   \n",
       "20570                                          Sweetness          0.054299   \n",
       "48836                                         Since Drew          0.053994   \n",
       "28361                               Wildcard: Volume One          0.054957   \n",
       "\n",
       "       weightedRating  \n",
       "46343        0.600926  \n",
       "9741         0.592836  \n",
       "3423         0.592157  \n",
       "47255        0.590361  \n",
       "45442        0.585887  \n",
       "41270        0.564635  \n",
       "42006        0.562513  \n",
       "20570        0.547539  \n",
       "48836        0.545907  \n",
       "28361        0.532547  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['title'].iloc[0])\n",
    "get_recommendations(df['title'].iloc[0], 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
