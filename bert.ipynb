{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINNING MEANS FAME AND FORTUNE.LOSING MEANS CERTAIN DEATH.THE HUNGER GAMES HAVE BEGUN. . . .In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and once girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV.Sixteen-year-old Katniss Everdeen regards it as a death sentence when she steps forward to take her sister's place in the Games. But Katniss has been close to dead before—and survival, for her, is second nature. Without really meaning to, she becomes a contender. But if she is to win, she will have to start making choices that weight survival against humanity and life against love.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\booklist.csv', index_col=False)\n",
    "\n",
    "col_names=['bookId','title','series','author','rating','description','lang','isbn','genres','characters','bookForm','edition','pages','publisher','publishDate','firstPublished','awards','numRating','ratingsByStars','likedPercent','setting','coverImg','bbeScore','bbeVotes','price']\n",
    "wanted_cols = ['bookId','title','series','author','rating','description','genres','characters','setting','coverImg']\n",
    "\n",
    "filtered_df = df[wanted_cols].head(5)\n",
    "df = df.head(10000)\n",
    "\n",
    "# print(df['description'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.5472, 0.6330]])\n",
      "tensor([[0.5472, 0.6330]])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "query_embedding = model.encode('How big is London')\n",
    "passage_embedding = model.encode(['London has 9,787,426 inhabitants at the 2011 census',\n",
    "                                  'London is known for its finacial district'])\n",
    "\n",
    "print(\"Similarity:\", util.dot_score(query_embedding, passage_embedding))\n",
    "print(util.cos_sim(query_embedding,passage_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 736/736 [00:00<00:00, 243kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 182kB/s]\n",
      "Downloading: 100%|██████████| 3.68k/3.68k [00:00<00:00, 1.14MB/s]\n",
      "Downloading: 100%|██████████| 627/627 [00:00<00:00, 604kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 61.5kB/s]\n",
      "Downloading: 100%|██████████| 90.9M/90.9M [00:08<00:00, 10.1MB/s]  \n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 15.8kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 22.4kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:01<00:00, 381kB/s]  \n",
      "Downloading: 100%|██████████| 430/430 [00:00<00:00, 71.1kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 246kB/s]  \n",
      "Downloading: 100%|██████████| 229/229 [00:00<00:00, 115kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.6061]])\n"
     ]
    }
   ],
   "source": [
    "#SEMANTIC SEARCH\n",
    "model = SentenceTransformer('msmarco-MiniLM-L-6-v3') #ms marco models for asymmetric semantic search (https://www.sbert.net/examples/applications/semantic-search/README.html)\n",
    "\n",
    "query_embedding = model.encode('How big is London')\n",
    "passage_embedding = model.encode('London has 9,787,426 inhabitants at the 2011 census')\n",
    "\n",
    "print(\"Similarity:\", util.cos_sim(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "tensor([[ 0.1455,  0.4684, -0.0570,  0.1316,  0.1725,  0.0641,  0.0705,  0.2217,\n",
      "          0.2930,  0.0423, -0.0801,  0.0227, -0.0327,  0.1124,  0.0999,  0.0032,\n",
      "          0.0251, -0.0505,  0.0383,  0.0826, -0.0773,  0.0019,  0.0339,  0.1310,\n",
      "          0.0779,  0.1273,  0.0232,  0.0335,  0.1238,  0.0747,  0.0478,  0.0074,\n",
      "          0.5455, -0.0601, -0.0692,  0.1075, -0.0484,  0.1511,  0.2627,  0.0352,\n",
      "          0.1395, -0.0025,  0.1626,  0.0933,  0.1485,  0.0821,  0.1566, -0.0006,\n",
      "         -0.1008,  0.0186]])\n",
      "tensor([[32,  1,  8, 38,  7,  4, 42, 46, 37, 44]])\n",
      "Harry Potter and the Sorcerer's Stone\n",
      "Harry Potter and the Order of the Phoenix\n",
      "J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings\n",
      "Brave New World\n",
      "The Chronicles of Narnia\n",
      "Twilight\n",
      "The Lightning Thief\n",
      "A Game of Thrones\n",
      "Dracula\n",
      "A Thousand Splendid Suns\n"
     ]
    }
   ],
   "source": [
    "x = df['description'].iloc[0]\n",
    "print(type(x))\n",
    "\n",
    "def clean_and_tokenize(x):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    d = re.sub(r'[^a-zA-Z0-9\\s]', ' ', x, re.I|re.A)\n",
    "    d = d.lower().strip()\n",
    "    # nltk.download('punkt')\n",
    "    tks = word_tokenize(d)\n",
    "    f_tks = [t for t in tks if t not in stopwords]\n",
    "    return ' '.join(f_tks)\n",
    "\n",
    "\n",
    "\n",
    "# print(df['description'].to_numpy())\n",
    "np_df = df['description'].to_numpy()\n",
    "v_clean_tokenize = np.vectorize(clean_and_tokenize)\n",
    "clean_df = v_clean_tokenize(np_df)\n",
    "encoded_df = model.encode(clean_df)\n",
    "\n",
    "def get_top_k_recos(query,k):\n",
    "    qry_e = model.encode(query)\n",
    "    scores = util.cos_sim(qry_e,encoded_df)\n",
    "    # print(torch.topk(scores,k))\n",
    "    vals,indices = torch.topk(scores,k)\n",
    "    # print(indices)\n",
    "    for i in indices[0].numpy():\n",
    "        print(df['title'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1404,  0.3336,  0.0081,  0.2122,  0.2114,  0.0761,  0.1129,  0.2133,\n",
      "          0.2926,  0.1169,  0.1255,  0.0478, -0.0302,  0.1544,  0.0172, -0.0856,\n",
      "          0.0030, -0.0304, -0.0027,  0.0573, -0.0498,  0.0021,  0.0876,  0.1139,\n",
      "         -0.0209,  0.1502, -0.0340,  0.1112,  0.0685,  0.1476,  0.0523,  0.0012,\n",
      "          0.3676,  0.0352, -0.0587, -0.0333, -0.0054,  0.0894,  0.1896,  0.0170,\n",
      "          0.0749,  0.0505,  0.1480,  0.0215,  0.2208,  0.0518,  0.1837, -0.0102,\n",
      "         -0.0585,  0.0340]])\n",
      "tensor([[32,  1,  8, 44,  7,  3,  4, 38, 46, 13]])\n",
      "Harry Potter and the Sorcerer's Stone\n",
      "Harry Potter and the Order of the Phoenix\n",
      "J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings\n",
      "A Thousand Splendid Suns\n",
      "The Chronicles of Narnia\n",
      "Pride and Prejudice\n",
      "Twilight\n",
      "Brave New World\n",
      "A Game of Thrones\n",
      "Wuthering Heights\n"
     ]
    }
   ],
   "source": [
    "get_top_k_recos(\"Harry Potter and the Order of the Phoenix\",20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
